{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Resume Base Training (Notebook Workflow)\n",
        "\n",
        "This notebook clones the DiffiT LoRA repository, installs dependencies, and resumes base model training from an existing checkpoint. Update the configuration cell before launching the training step.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Clone the Repository\n",
        "\n",
        "Run this cell once per environment. If the repository already exists, it will skip cloning and just set the working directory.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "REPO_URL = \"https://github.com/drhspeco/diffit-lora.git\"\n",
        "TARGET_DIR = Path(\"diffit-lora\")\n",
        "\n",
        "if (Path.cwd() / \".git\").exists():\n",
        "    project_root = Path.cwd()\n",
        "    print(f\"Repository already available at {project_root}\")\n",
        "else:\n",
        "    if TARGET_DIR.exists():\n",
        "        project_root = TARGET_DIR.resolve()\n",
        "        print(f\"Repository already present at {project_root}\")\n",
        "    else:\n",
        "        print(f\"Cloning {REPO_URL} ...\")\n",
        "        !git clone {REPO_URL}\n",
        "        project_root = TARGET_DIR.resolve()\n",
        "    os.chdir(project_root)\n",
        "    print(f\"Working directory set to {Path.cwd()}\")\n",
        "\n",
        "if not (Path.cwd() / \".git\").exists():\n",
        "    raise RuntimeError(\"Could not locate the diffit-lora repository. Update TARGET_DIR or run the cell again from the correct location.\")\n",
        "\n",
        "sys.path.insert(0, str(Path.cwd()))\n",
        "print(\"sys.path updated for local imports.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. (Optional) Mount Google Drive\n",
        "\n",
        "Run this cell when working in Google Colab so checkpoints and configs stored in Drive are available.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    from google.colab import drive  # type: ignore\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"Google Drive mounted.\")\n",
        "except ImportError:\n",
        "    print(\"Google Colab not detected; skipping Drive mount.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Install Dependencies\n",
        "\n",
        "Make sure the required Python packages are installed. Comment out packages you already have.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -q -r requirements.txt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Configure Paths and Hyperparameters\n",
        "\n",
        "Update the variables below to point to your checkpoints, config files, and desired overrides before starting the training job.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# Attempt to use Google Drive copy when available; fall back to local repo directory.\n",
        "default_drive_root = Path(\"/content/drive/MyDrive/diffit-lora\")\n",
        "PROJECT_ROOT = default_drive_root if default_drive_root.exists() else Path.cwd()\n",
        "\n",
        "# Paths to important assets\n",
        "CHECKPOINT_TO_RESUME = PROJECT_ROOT / \"checkpoints\" / \"base\" / \"base_model_last.ckpt\"\n",
        "TRAINING_CONFIG_PATH = PROJECT_ROOT / \"configs\" / \"training\" / \"base_training.yaml\"\n",
        "MODEL_CONFIG_PATH = PROJECT_ROOT / \"configs\" / \"models\" / \"unet_config.yaml\"\n",
        "DATA_CONFIG_PATH = None  # Optional explicit path; leave as None to resolve from DATASET_NAME\n",
        "\n",
        "# Training overrides (set to None to keep YAML values)\n",
        "DATASET_NAME = None          # Examples: \"CIFAR\", \"CIFAR100\", \"imagenette\"\n",
        "NUM_EPOCHS = None            # e.g., 5\n",
        "LEARNING_RATE = None         # e.g., 5e-4\n",
        "BATCH_SIZE = None            # If provided, overrides data config batch size\n",
        "ACCELERATOR = None           # e.g., \"gpu\", \"cpu\", \"mps\"\n",
        "DEVICES = None               # e.g., 1 or \"auto\"\n",
        "PRECISION = None             # e.g., \"16-mixed\"\n",
        "GRADIENT_CLIP_VAL = None\n",
        "LOG_EVERY_N_STEPS = None\n",
        "\n",
        "# Model overrides (defaults defined in configs/models/unet_config.yaml)\n",
        "MODEL_OVERRIDES = {\n",
        "    \"d_model\": None,\n",
        "    \"num_heads\": None,\n",
        "    \"dropout\": None,\n",
        "    \"d_ff\": None,\n",
        "    \"img_size\": None,\n",
        "    \"denoising_steps\": None,\n",
        "    \"L1\": None,\n",
        "    \"L2\": None,\n",
        "    \"L3\": None,\n",
        "    \"L4\": None,\n",
        "}\n",
        "\n",
        "# Output management\n",
        "OUTPUT_DIR = PROJECT_ROOT / \"checkpoints\" / \"base_training\"\n",
        "EXPERIMENT_NAME = \"diffit_base_resumed\"\n",
        "KEEP_LAST_N = 3\n",
        "SAVE_EVERY_N_EPOCHS = 1\n",
        "\n",
        "# Execution toggle\n",
        "RUN_TRAINING = False  # Switch to True when you are ready to launch training.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Resume Training Helper\n",
        "\n",
        "The function below mirrors `resume_base_training.py` but exposes configuration overrides for notebook use.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import yaml\n",
        "import torch\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import LearningRateMonitor\n",
        "\n",
        "from diffit.training.base_checkpoint_callbacks import BaseModelCheckpointCallback\n",
        "from diffit.training.data import DiffiTDataModule\n",
        "from diffit.models.unet import UShapedNetwork\n",
        "\n",
        "\n",
        "def _resolve_data_config_path(dataset_name: str, project_root: Path) -> Path:\n",
        "    dataset_key = dataset_name.upper()\n",
        "    data_dir = project_root / \"configs\" / \"data\"\n",
        "\n",
        "    if dataset_key == \"CIFAR\":\n",
        "        candidate = data_dir / \"cifar10.yaml\"\n",
        "    elif dataset_key == \"CIFAR100\":\n",
        "        candidate = data_dir / \"cifar100.yaml\"\n",
        "    else:\n",
        "        candidate = data_dir / f\"{dataset_name.lower()}.yaml\"\n",
        "\n",
        "    if not candidate.exists():\n",
        "        raise FileNotFoundError(f\"Could not find data config for dataset '{dataset_name}' at {candidate}.\")\n",
        "\n",
        "    return candidate\n",
        "\n",
        "\n",
        "def _load_model_config(model_config_path: Path, model_overrides: dict | None) -> tuple[dict, torch.device]:\n",
        "    with open(model_config_path, \"r\") as f:\n",
        "        model_yaml = yaml.safe_load(f) or {}\n",
        "\n",
        "    model_cfg = dict(model_yaml.get(\"model\", {}))\n",
        "    if model_overrides:\n",
        "        for key, value in model_overrides.items():\n",
        "            if value is not None:\n",
        "                model_cfg[key] = value\n",
        "\n",
        "    device_pref = model_overrides.get(\"device\") if model_overrides else None\n",
        "    if device_pref is None:\n",
        "        device_pref = model_yaml.get(\"device\", \"auto\")\n",
        "\n",
        "    if device_pref == \"auto\":\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    else:\n",
        "        device = torch.device(device_pref)\n",
        "\n",
        "    return model_cfg, device\n",
        "\n",
        "\n",
        "def resume_base_training_notebook(\n",
        "    checkpoint_path: Path,\n",
        "    training_config_path: Path,\n",
        "    output_dir: Path,\n",
        "    experiment_name: str = \"diffit_base_resumed\",\n",
        "    dataset_name: str | None = None,\n",
        "    data_config_path: Path | None = None,\n",
        "    num_epochs: int | None = None,\n",
        "    learning_rate: float | None = None,\n",
        "    batch_size: int | None = None,\n",
        "    accelerator: str | None = None,\n",
        "    devices: str | int | list[int] | None = None,\n",
        "    precision: str | None = None,\n",
        "    gradient_clip_val: float | None = None,\n",
        "    log_every_n_steps: int | None = None,\n",
        "    model_config_path: Path | None = None,\n",
        "    model_overrides: dict | None = None,\n",
        "    keep_last_n: int = 3,\n",
        "    save_every_n_epochs: int = 1,\n",
        "    run_training: bool = False,\n",
        ") -> dict:\n",
        "    \"\"\"Resume base training from a checkpoint with notebook-friendly overrides.\"\"\"\n",
        "\n",
        "    checkpoint_path = checkpoint_path.expanduser().resolve()\n",
        "    training_config_path = training_config_path.expanduser().resolve()\n",
        "    output_dir = output_dir.expanduser().resolve()\n",
        "\n",
        "    if not checkpoint_path.exists():\n",
        "        raise FileNotFoundError(f\"Checkpoint not found at {checkpoint_path}\")\n",
        "    if not training_config_path.exists():\n",
        "        raise FileNotFoundError(f\"Training config not found at {training_config_path}\")\n",
        "\n",
        "    with open(training_config_path, \"r\") as f:\n",
        "        training_yaml = yaml.safe_load(f) or {}\n",
        "\n",
        "    training_cfg = dict(training_yaml.get(\"training\", {}))\n",
        "\n",
        "    if dataset_name is not None:\n",
        "        training_cfg[\"dataset\"] = dataset_name\n",
        "    if num_epochs is not None:\n",
        "        training_cfg[\"num_epochs\"] = num_epochs\n",
        "    if learning_rate is not None:\n",
        "        training_cfg[\"learning_rate\"] = learning_rate\n",
        "    if accelerator is not None:\n",
        "        training_cfg[\"accelerator\"] = accelerator\n",
        "    if devices is not None:\n",
        "        training_cfg[\"devices\"] = devices\n",
        "    if precision is not None:\n",
        "        training_cfg[\"precision\"] = precision\n",
        "    if gradient_clip_val is not None:\n",
        "        training_cfg[\"gradient_clip_val\"] = gradient_clip_val\n",
        "    if log_every_n_steps is not None:\n",
        "        training_cfg[\"log_every_n_steps\"] = log_every_n_steps\n",
        "\n",
        "    resolved_dataset = training_cfg.get(\"dataset\", \"CIFAR\")\n",
        "    if data_config_path is None:\n",
        "        parents = training_config_path.parents\n",
        "        project_root = parents[2] if len(parents) >= 3 else parents[-1]\n",
        "        data_config_path = _resolve_data_config_path(resolved_dataset, project_root)\n",
        "\n",
        "    with open(data_config_path, \"r\") as f:\n",
        "        data_config = yaml.safe_load(f) or {}\n",
        "\n",
        "    if batch_size is not None:\n",
        "        data_section = data_config.setdefault(\"data\", {})\n",
        "        data_section[\"batch_size_train\"] = batch_size\n",
        "        if \"batch_size_test\" in data_section and batch_size < data_section[\"batch_size_test\"]:\n",
        "            print(\"âš ï¸ batch_size override is smaller than batch_size_test; adjust test batch size if needed.\")\n",
        "\n",
        "    if model_config_path is None:\n",
        "        raise ValueError(\"model_config_path must be provided.\")\n",
        "\n",
        "    model_cfg, device = _load_model_config(model_config_path.expanduser().resolve(), model_overrides or {})\n",
        "    model_cfg.setdefault(\"learning_rate\", training_cfg.get(\"learning_rate\", 1e-3))\n",
        "    model_cfg[\"learning_rate\"] = training_cfg.get(\"learning_rate\", model_cfg.get(\"learning_rate\", 1e-3))\n",
        "\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    checkpoint_callback = BaseModelCheckpointCallback(\n",
        "        base_dir=str(output_dir),\n",
        "        run_number=None,\n",
        "        experiment_name=experiment_name,\n",
        "        monitor=\"train_loss\",\n",
        "        mode=\"min\",\n",
        "        save_every_n_epochs=save_every_n_epochs,\n",
        "        keep_last_n=keep_last_n,\n",
        "        verbose=True,\n",
        "    )\n",
        "\n",
        "    lr_monitor = LearningRateMonitor(logging_interval=\"step\")\n",
        "    callbacks = [checkpoint_callback, lr_monitor]\n",
        "\n",
        "    data_module = DiffiTDataModule(data_config)\n",
        "\n",
        "    trainer = pl.Trainer(\n",
        "        max_epochs=training_cfg.get(\"num_epochs\", 3),\n",
        "        callbacks=callbacks,\n",
        "        accelerator=training_cfg.get(\"accelerator\", \"auto\"),\n",
        "        devices=training_cfg.get(\"devices\", \"auto\"),\n",
        "        precision=training_cfg.get(\"precision\", \"32-true\"),\n",
        "        gradient_clip_val=training_cfg.get(\"gradient_clip_val\", 1.0),\n",
        "        log_every_n_steps=training_cfg.get(\"log_every_n_steps\", 25),\n",
        "        default_root_dir=str(checkpoint_callback.logs_dir),\n",
        "    )\n",
        "\n",
        "    model = UShapedNetwork(\n",
        "        learning_rate=model_cfg[\"learning_rate\"],\n",
        "        d_model=model_cfg[\"d_model\"],\n",
        "        num_heads=model_cfg[\"num_heads\"],\n",
        "        dropout=model_cfg[\"dropout\"],\n",
        "        d_ff=model_cfg[\"d_ff\"],\n",
        "        img_size=model_cfg[\"img_size\"],\n",
        "        device=device,\n",
        "        denoising_steps=model_cfg[\"denoising_steps\"],\n",
        "        L1=model_cfg.get(\"L1\", 2),\n",
        "        L2=model_cfg.get(\"L2\", 2),\n",
        "        L3=model_cfg.get(\"L3\", 2),\n",
        "        L4=model_cfg.get(\"L4\", 2),\n",
        "    )\n",
        "\n",
        "    print(\"\\nðŸ”„ Resuming Base Model Training\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"Checkpoint: {checkpoint_path}\")\n",
        "    print(f\"Dataset config: {data_config_path}\")\n",
        "    print(f\"Training config: {training_config_path}\")\n",
        "    print(f\"Output directory: {checkpoint_callback.run_dir}\")\n",
        "    print(f\"Device: {device}\")\n",
        "\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=\"cpu\")\n",
        "    starting_epoch = checkpoint.get(\"epoch\", 0)\n",
        "    checkpoint_callback.set_starting_epoch(starting_epoch)\n",
        "\n",
        "    checkpoint_fixed = False\n",
        "    if \"pytorch-lightning_version\" not in checkpoint:\n",
        "        checkpoint[\"pytorch-lightning_version\"] = pl.__version__\n",
        "        checkpoint_fixed = True\n",
        "    if \"optimizer_states\" not in checkpoint:\n",
        "        checkpoint[\"optimizer_states\"] = []\n",
        "        checkpoint[\"lr_schedulers\"] = []\n",
        "        checkpoint[\"optimizer_state_dict\"] = None\n",
        "        checkpoint[\"scheduler_state_dict\"] = None\n",
        "        checkpoint_fixed = True\n",
        "        print(\"ðŸ”§ Added missing optimizer/scheduler states (weights-only checkpoint)\")\n",
        "\n",
        "    checkpoint_to_use = checkpoint_path\n",
        "    if checkpoint_fixed:\n",
        "        checkpoint_to_use = output_dir / \"temp_fixed_checkpoint.ckpt\"\n",
        "        torch.save(checkpoint, checkpoint_to_use)\n",
        "        print(f\"ðŸ”§ Fixed checkpoint compatibility - saved to: {checkpoint_to_use}\")\n",
        "\n",
        "    print(f\"ðŸ“Š Continuing from epoch {starting_epoch + 1}\")\n",
        "\n",
        "    if run_training:\n",
        "        trainer.fit(model, datamodule=data_module, ckpt_path=str(checkpoint_to_use))\n",
        "        print(\"Training complete.\")\n",
        "    else:\n",
        "        print(\"Dry run complete. Set run_training=True to start training.\")\n",
        "\n",
        "    if checkpoint_fixed and checkpoint_to_use.exists():\n",
        "        checkpoint_to_use.unlink()\n",
        "        print(\"ðŸ§¹ Cleaned up temporary checkpoint file.\")\n",
        "\n",
        "    return {\n",
        "        \"trainer\": trainer,\n",
        "        \"model\": model,\n",
        "        \"data_module\": data_module,\n",
        "        \"checkpoint_callback\": checkpoint_callback,\n",
        "        \"training_config\": training_cfg,\n",
        "        \"data_config_path\": data_config_path,\n",
        "    }\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Launch (or Dry Run) Training\n",
        "\n",
        "Execute the cell below after reviewing the configuration. Set `RUN_TRAINING = True` in the configuration cell to actually start training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import display\n",
        "\n",
        "results = resume_base_training_notebook(\n",
        "    checkpoint_path=CHECKPOINT_TO_RESUME,\n",
        "    training_config_path=TRAINING_CONFIG_PATH,\n",
        "    output_dir=OUTPUT_DIR,\n",
        "    experiment_name=EXPERIMENT_NAME,\n",
        "    dataset_name=DATASET_NAME,\n",
        "    data_config_path=DATA_CONFIG_PATH,\n",
        "    num_epochs=NUM_EPOCHS,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    accelerator=ACCELERATOR,\n",
        "    devices=DEVICES,\n",
        "    precision=PRECISION,\n",
        "    gradient_clip_val=GRADIENT_CLIP_VAL,\n",
        "    log_every_n_steps=LOG_EVERY_N_STEPS,\n",
        "    model_config_path=MODEL_CONFIG_PATH,\n",
        "    model_overrides=MODEL_OVERRIDES,\n",
        "    keep_last_n=KEEP_LAST_N,\n",
        "    save_every_n_epochs=SAVE_EVERY_N_EPOCHS,\n",
        "    run_training=RUN_TRAINING,\n",
        ")\n",
        "\n",
        "display({\n",
        "    \"next_checkpoint_dir\": str(results[\"checkpoint_callback\"].checkpoint_dir),\n",
        "    \"log_dir\": str(results[\"checkpoint_callback\"].logs_dir),\n",
        "    \"resolved_dataset_config\": str(results[\"data_config_path\"]),\n",
        "    \"current_training_config\": results[\"training_config\"],\n",
        "})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Next Steps\n",
        "\n",
        "- Inspect the returned training configuration to confirm overrides.\n",
        "- Adjust dataset or model overrides as needed, then set `RUN_TRAINING = True` and re-run the launch cell.\n",
        "- Monitor checkpoint and log folders reported in the output for progress.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
