# Quick Start: Trees Fine-tuning with Checkpoint Management

## ğŸ¯ What You Have Now

A complete distributed checkpoint management system for DiffiT LoRA fine-tuning with:

âœ… **Run numbering** - Automatic experiment tracking  
âœ… **Distributed checkpoints** - Separate LoRA and base model storage  
âœ… **Resume capability** - Continue training from any run  
âœ… **Auto-cleanup** - Saves disk space by keeping only recent checkpoints  
âœ… **Trees dataset** - CIFAR-100 filtered to 5 tree classes  

## ğŸ“ What Was Created

### New Files:
- `diffit/utils/checkpoint_manager.py` - Core checkpoint management system
- `diffit/training/checkpoint_callbacks.py` - PyTorch Lightning callbacks  
- `diffit/utils/cifar100_classes.py` - CIFAR-100 class filtering utilities
- `run_trees_finetuning_with_checkpoints.py` - Example training script
- `CHECKPOINT_MANAGEMENT.md` - Complete documentation
- `configs/data/cifar100_trees_only.yaml` - Trees dataset config

### Updated Files:
- `configs/training/lora_finetuning.yaml` - Added checkpoint management config
- `diffit/training/data.py` - Added class filtering support

## ğŸš€ How to Run Trees Fine-tuning

### Method 1: Using the Checkpoint Manager Script (Recommended)

```bash
# Start a new training run (creates run_001)
python run_trees_finetuning_with_checkpoints.py

# Resume from run 2
python run_trees_finetuning_with_checkpoints.py --run-number 2 --resume

# List all runs
python run_trees_finetuning_with_checkpoints.py --list-runs

# Custom parameters
python run_trees_finetuning_with_checkpoints.py \
  --epochs 10 \
  --batch-size 64 \
  --learning-rate 1e-4
```

### Method 2: Using Python API

```python
from diffit.utils.checkpoint_manager import CheckpointManager
from diffit.training.checkpoint_callbacks import DistributedCheckpointCallback
import pytorch_lightning as pl

# Create checkpoint manager (auto-increments run number)
checkpoint_manager = CheckpointManager(
    base_dir="checkpoints",
    experiment_name="diffit_lora_trees"
)

# Load your model and data
# model = ...
# data_module = ...

# Setup checkpoint callback
checkpoint_callback = DistributedCheckpointCallback(
    checkpoint_manager=checkpoint_manager,
    monitor='val_loss',
    mode='min'
)

# Train
trainer = pl.Trainer(callbacks=[checkpoint_callback])
trainer.fit(model, datamodule=data_module)
```

## ğŸ“‚ Checkpoint Directory Structure

After running, you'll see:

```
checkpoints/
â”œâ”€â”€ run_001/                         â† First training run
â”‚   â”œâ”€â”€ config.json                  â† Training configuration
â”‚   â”œâ”€â”€ metadata.json                 â† Run metadata
â”‚   â”œâ”€â”€ base_model/
â”‚   â”‚   â””â”€â”€ base_model.ckpt          â† Base model (saved once, ~500MB)
â”‚   â”œâ”€â”€ lora_weights/
â”‚   â”‚   â”œâ”€â”€ epoch_001.ckpt           â† LoRA weights per epoch (~25MB each)
â”‚   â”‚   â”œâ”€â”€ epoch_002.ckpt
â”‚   â”‚   â”œâ”€â”€ epoch_003.ckpt
â”‚   â”‚   â”œâ”€â”€ best.ckpt                 â† Best checkpoint
â”‚   â”‚   â””â”€â”€ last.ckpt                 â† Last checkpoint (for resume)
â”‚   â””â”€â”€ logs/                         â† TensorBoard logs
â”œâ”€â”€ run_002/                         â† Second training run
â”‚   â””â”€â”€ ...
â””â”€â”€ run_003/                         â† Third training run
    â””â”€â”€ ...
```

## ğŸŒ³ Trees Dataset Details

**Classes (5 total):**
- maple_tree (index 47)
- oak_tree (index 52)
- palm_tree (index 56)
- pine_tree (index 59)
- willow_tree (index 96)

**Dataset Size:**
- Training: 2,250 samples (after 90/10 split)
- Validation: 750 samples
- Image format: 32x32 RGB
- Normalized to [-1, 1]

## ğŸ’¾ Disk Space Savings

**Traditional checkpointing (10 epochs):**
- Full model Ã— 10 epochs = 500MB Ã— 10 = **5 GB**

**Distributed checkpointing (10 epochs):**
- Base model (once) = 500MB
- LoRA weights Ã— 10 = 25MB Ã— 10 = 250MB
- **Total: 750 MB** (85% savings!)

## ğŸ”„ Resume Training Workflow

### Scenario: Training interrupted at epoch 3

```bash
# Original training
python run_trees_finetuning_with_checkpoints.py
# Creates run_001, trains epochs 1-3, then crashes

# Resume from where it left off
python run_trees_finetuning_with_checkpoints.py --run-number 1 --resume
# Loads last.ckpt from run_001, continues from epoch 4
```

The system automatically:
- âœ… Loads LoRA weights from last checkpoint
- âœ… Restores optimizer state
- âœ… Restores scheduler state  
- âœ… Resumes from correct epoch
- âœ… Preserves all metrics

## ğŸ“Š Example Training Session

```bash
# Session 1: Initial training
$ python run_trees_finetuning_with_checkpoints.py --epochs 5
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  Checkpoint Manager - Run 001
â•‘  Experiment: diffit_lora_trees
â•‘  Checkpoints: 0
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Epoch 1/5: train_loss=0.456, val_loss=0.234
Epoch 2/5: train_loss=0.234, val_loss=0.189
Epoch 3/5: [CRASH!]

# Session 2: Resume training
$ python run_trees_finetuning_with_checkpoints.py --run-number 1 --resume
ğŸ“¥ Resuming from checkpoint...
âœ… Resumed from epoch 3

Epoch 4/5: train_loss=0.198, val_loss=0.176  â† Best!
Epoch 5/5: train_loss=0.187, val_loss=0.181

ğŸ‰ Training completed!
â­ Best checkpoint: Epoch 4, val_loss=0.176

# Session 3: Try different hyperparameters
$ python run_trees_finetuning_with_checkpoints.py \
    --epochs 5 \
    --learning-rate 1e-5
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  Checkpoint Manager - Run 002
â•‘  Experiment: diffit_lora_trees
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Session 4: List all experiments
$ python run_trees_finetuning_with_checkpoints.py --list-runs
ğŸ“‹ Available Training Runs:
Run #    Experiment              Created               Checkpoints
1        diffit_lora_trees       2025-01-15 10:30:00  5
2        diffit_lora_trees       2025-01-15 14:20:00  5
```

## ğŸ” Loading Checkpoints for Inference

```python
from diffit.utils.checkpoint_manager import CheckpointManager

# Load run 1
checkpoint_manager = CheckpointManager(
    base_dir="checkpoints",
    run_number=1
)

# Load base model
base_ckpt = checkpoint_manager.load_base_model()
model.load_state_dict(base_ckpt['state_dict'], strict=False)

# Load best LoRA weights
lora_ckpt = checkpoint_manager.load_lora_weights(load_best=True)
model.load_state_dict(lora_ckpt['lora_state_dict'], strict=False)

# Model is now ready for inference!
```

## ğŸ¨ Other Available Datasets

You can also fine-tune on other CIFAR-100 subsets:

```yaml
# Animals (40 classes)
configs/data/cifar100_animals_only.yaml

# Vehicles (10 classes)
configs/data/cifar100_vehicles_only.yaml

# Trees (5 classes) 
configs/data/cifar100_trees_only.yaml

# Full CIFAR-100 (100 classes)
configs/data/cifar100.yaml

# Custom filtering
configs/data/cifar100.yaml:
  class_filter:
    enabled: true
    classes: [0, 1, 2, 3, 4]  # First 5 classes
```

## ğŸ› ï¸ Configuration Reference

### Checkpoint Settings (`configs/training/lora_finetuning.yaml`)

```yaml
training:
  checkpoint:
    enabled: true               # Enable checkpoint management
    base_dir: "checkpoints"     # Base directory
    run_number: null            # null = auto-increment, or specify number
    save_every_n_epochs: 1      # Save frequency
    keep_last_n: 5              # Number of checkpoints to keep
    monitor: "val_loss"         # Metric to monitor
    mode: "min"                 # min or max
    save_base_model: true       # Save base model separately
    resume_from_run: null       # Run to resume from
```

## ğŸš¨ Common Issues

### "Base model not found"
```bash
# Make sure you have a trained base model
ls checkpoints/base/base_model_last.ckpt

# Or train one first
python scripts/train_base_model.py
```

### "Run already exists"
```bash
# To start fresh, delete the old run
rm -rf checkpoints/run_001

# Or specify a different run number
python run_trees_finetuning_with_checkpoints.py --run-number 999
```

### "Out of disk space"
```bash
# Cleanup old checkpoints
python -c "
from diffit.utils.checkpoint_manager import CheckpointManager
cm = CheckpointManager(run_number=1)
cm.cleanup_old_checkpoints(keep_last_n=2, keep_best=True)
"
```

## ğŸ“š Next Steps

1. **Read the full documentation**: `CHECKPOINT_MANAGEMENT.md`
2. **Integrate with your model**: Update `run_trees_finetuning_with_checkpoints.py`
3. **Experiment with hyperparameters**: Try different learning rates, batch sizes
4. **Compare runs**: Use the run numbering to track experiments
5. **Deploy the best model**: Load `best.ckpt` for production

## ğŸ’¡ Pro Tips

1. **Always use meaningful experiment names** for organization
2. **Set `keep_last_n` based on disk space** (3-5 is usually good)
3. **Use TensorBoard** to visualize training across runs
4. **Export metadata** for experiment tracking
5. **Clean up old runs** periodically

## ğŸ“ Integration Example

```python
# Full integration with your training pipeline
from diffit.utils.checkpoint_manager import CheckpointManager
from diffit.training.checkpoint_callbacks import (
    DistributedCheckpointCallback,
    ResumeFromCheckpointCallback
)
from diffit.training.data import DiffiTDataModule
import pytorch_lightning as pl

# Initialize checkpoint manager
checkpoint_manager = CheckpointManager(
    base_dir="checkpoints",
    experiment_name="diffit_lora_trees",
    run_number=None  # Auto-increment
)

# Load data
with open('configs/data/cifar100_trees_only.yaml') as f:
    data_config = yaml.safe_load(f)
data_module = DiffiTDataModule(data_config)

# Initialize model
# model = YourDiffiTModel(...)

# Setup callbacks
callbacks = [
    DistributedCheckpointCallback(
        checkpoint_manager=checkpoint_manager,
        monitor='val_loss',
        mode='min'
    )
]

# Train
trainer = pl.Trainer(
    max_epochs=10,
    callbacks=callbacks,
    accelerator='auto'
)
trainer.fit(model, datamodule=data_module)

# After training, load best checkpoint
lora_ckpt = checkpoint_manager.load_lora_weights(load_best=True)
print(f"Best checkpoint metrics: {lora_ckpt['metrics']}")
```

## âœ… Summary

You now have a complete, production-ready checkpoint management system that:

- âœ… Automatically numbers training runs
- âœ… Saves LoRA and base model separately
- âœ… Enables resuming from any checkpoint
- âœ… Tracks all metadata and metrics
- âœ… Saves 85%+ disk space
- âœ… Works with PyTorch Lightning
- âœ… Supports trees (and other) dataset filtering

**Happy training! ğŸŒ³ğŸš€**
